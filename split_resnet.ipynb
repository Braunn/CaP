{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Load RESNET model and split it\\n        1. layer by layer\\n        2. [TODO] vertically \\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Load RESNET model and split it\n",
    "        1. layer by layer\n",
    "        2. [TODO] vertically \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.core.engine import MoP\n",
    "import source.core.run_partition as run_p\n",
    "from os import environ\n",
    "from source.utils.dataset import *\n",
    "from source.utils.misc import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from source.models import resnet\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from source.utils import io\n",
    "import json\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  \n",
      "model :  resnet18\n",
      "data_code :  cifar10\n",
      "num_classes :  10\n",
      "model_file :  test.pt\n",
      "epochs :  0\n",
      "batch_size :  128\n",
      "optimizer :  sgd\n",
      "lr_scheduler :  default\n",
      "learning_rate :  0.01\n",
      "seed :  1234\n",
      "sparsity_type :  kernel\n",
      "prune_ratio :  1\n",
      "admm :  True\n",
      "admm_epochs :  3\n",
      "rho :  0.0001\n",
      "multi_rho :  True\n",
      "retrain_bs :  128\n",
      "retrain_lr :  0.005\n",
      "retrain_ep :  50\n",
      "retrain_opt :  default\n",
      "xentropy_weight :  1.0\n",
      "warmup :  False\n",
      "warmup_lr :  0.001\n",
      "warmup_epochs :  10\n",
      "mix_up :  True\n",
      "alpha :  0.3\n",
      "smooth :  False\n",
      "smooth_eps :  0\n",
      "save_last_model_only :  False\n",
      "num_partition :  1\n",
      "layer_type :  regular\n",
      "bn_type :  masked\n",
      "par_first_layer :  False\n",
      "comm_outsize :  False\n",
      "lambda_comm :  0\n",
      "lambda_comp :  0\n",
      "distill_model :  \n",
      "distill_loss :  kl\n",
      "distill_temp :  30\n",
      "distill_alpha :  1\n"
     ]
    }
   ],
   "source": [
    "# setup config\n",
    "dataset='cifar10'\n",
    "environ[\"config\"] = f\"config/{dataset}.yaml\"\n",
    "\n",
    "configs = run_p.main()\n",
    "\n",
    "configs[\"device\"] = \"cuda:0\"\n",
    "configs['load_model'] = \"cifar10-resnet18-kernel-npv2-pr0.75-lcm0.001.pt\"\n",
    "configs[\"num_partition\"] = 'resnet18-v2.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load data and load or train model\n",
    "model = get_model_from_code(configs).to(configs['device']) # grabs model architecture from ./source/models/escnet.py\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   1st section of resnet model \n",
    "'''\n",
    "class ResnetBlockOne(nn.Module):\n",
    "    def __init__(self, block, num_blocks, conv_layer, bn_layer, num_classes=10, num_filters=512, bn_partition=[1]*9):\n",
    "        super(ResnetBlockOne, self).__init__()\n",
    "\n",
    "        self.in_planes = 64\n",
    "        self.conv_layer = conv_layer\n",
    "        self.bn_layer = bn_layer\n",
    "        self.shrink = num_filters/512\n",
    "        self.bn_partition = bn_partition\n",
    "        \n",
    "        self.conv1 = conv_layer(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        num_bn = self.bn_partition.pop(0)\n",
    "        self.bn1 = bn_layer(64) if num_bn==1 else bn_layer(64, num_bn)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, int(64*self.shrink),  num_blocks[0], stride=1)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        # TODO: find better way to implement this method using inheretence and getting from ResNet class\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, self.conv_layer, self.bn_layer, stride, self.bn_partition.pop(0)))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # override the the foward pass to only include the first modules \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "'''\n",
    "   2nd section of resnet model \n",
    "'''\n",
    "class ResnetBlockTwo(nn.Module):\n",
    "    def __init__(self, block, num_blocks, conv_layer, bn_layer, num_classes=10, num_filters=512, bn_partition=[1]*9):\n",
    "        super(ResnetBlockTwo, self).__init__()\n",
    "\n",
    "        self.in_planes = 64\n",
    "        self.conv_layer = conv_layer\n",
    "        self.bn_layer = bn_layer\n",
    "        self.shrink = num_filters/512\n",
    "        self.bn_partition = bn_partition\n",
    "\n",
    "        self.layer2 = self._make_layer(block, int(128*self.shrink), num_blocks[1], stride=2)\n",
    "    \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        # TODO: find better way to implement this method using inheretence and getting from ResNet class\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, self.conv_layer, self.bn_layer, stride, self.bn_partition.pop(0)))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer2(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "    3rd section of resenet model \n",
    "'''\n",
    "class ResnetBlockThree(nn.Module):\n",
    "    def __init__(self, block, num_blocks, conv_layer, bn_layer, num_classes=10, num_filters=512, bn_partition=[1]*9):\n",
    "        super(ResnetBlockThree, self).__init__()\n",
    "\n",
    "        self.in_planes = 128\n",
    "        self.conv_layer = conv_layer\n",
    "        self.bn_layer = bn_layer\n",
    "        self.shrink = num_filters/512\n",
    "        self.bn_partition = bn_partition\n",
    "\n",
    "        self.layer3 = self._make_layer(block, int(256*self.shrink), num_blocks[2], stride=2)\n",
    "    \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        # TODO: find better way to implement this method using inheretence and getting from ResNet class\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, self.conv_layer, self.bn_layer, stride, self.bn_partition.pop(0)))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer3(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "    4-th section of resenet model \n",
    "'''\n",
    "class ResnetBlockFour(nn.Module):\n",
    "    def __init__(self, block, num_blocks, conv_layer, bn_layer, num_classes=10, num_filters=512, bn_partition=[1]*9):\n",
    "        super(ResnetBlockFour, self).__init__()\n",
    "\n",
    "        self.in_planes = 256\n",
    "        self.conv_layer = conv_layer\n",
    "        self.bn_layer = bn_layer\n",
    "        self.shrink = num_filters/512\n",
    "        self.bn_partition = bn_partition\n",
    "\n",
    "        self.layer4 = self._make_layer(block, num_filters, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(num_filters*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        # TODO: find better way to implement this method using inheretence and getting from ResNet class\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, self.conv_layer, self.bn_layer, stride, self.bn_partition.pop(0)))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer4(x)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResnetBlockFour(\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# get framework for each layer of resnet\n",
    "\n",
    "# inputs can be found from looking at ./source/util/misc/get_model_from_code\n",
    "num_classes=configs['num_classes']\n",
    "bn_layers = get_bn_layers('regular') # basic block layer\n",
    "conv_layers = get_layers(configs['layer_type'])\n",
    "\n",
    "# resnet18 inputs from resnet.py\n",
    "layer_1 =  ResnetBlockOne(resnet.BasicBlock, [2,2,2,2],conv_layers, bn_layers, num_classes=num_classes) # also includes bn1 and conv1 \n",
    "layer_2 =  ResnetBlockTwo(resnet.BasicBlock, [2,2,2,2],conv_layers, bn_layers, num_classes=num_classes) # also includes bn1 and conv1 \n",
    "layer_3 =  ResnetBlockThree(resnet.BasicBlock, [2,2,2,2],conv_layers, bn_layers, num_classes=num_classes) # also includes bn1 and conv1 \n",
    "layer_4 =  ResnetBlockFour(resnet.BasicBlock, [2,2,2,2],conv_layers, bn_layers, num_classes=num_classes) # also includes bn1 and conv1 \n",
    "\n",
    "print(layer_4)\n",
    "#block2 = |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found:  layer2.0.conv1.weight\n",
      "not found:  layer2.0.conv2.weight\n",
      "not found:  layer2.0.bn1.weight\n",
      "not found:  layer2.0.bn1.bias\n",
      "not found:  layer2.0.bn1.running_mean\n",
      "not found:  layer2.0.bn1.running_var\n",
      "not found:  layer2.0.bn1.num_batches_tracked\n",
      "not found:  layer2.0.bn2.weight\n",
      "not found:  layer2.0.bn2.bias\n",
      "not found:  layer2.0.bn2.running_mean\n",
      "not found:  layer2.0.bn2.running_var\n",
      "not found:  layer2.0.bn2.num_batches_tracked\n",
      "not found:  layer2.0.shortcut.0.weight\n",
      "not found:  layer2.0.shortcut.1.weight\n",
      "not found:  layer2.0.shortcut.1.bias\n",
      "not found:  layer2.0.shortcut.1.running_mean\n",
      "not found:  layer2.0.shortcut.1.running_var\n",
      "not found:  layer2.0.shortcut.1.num_batches_tracked\n",
      "not found:  layer2.1.conv1.weight\n",
      "not found:  layer2.1.conv2.weight\n",
      "not found:  layer2.1.bn1.weight\n",
      "not found:  layer2.1.bn1.bias\n",
      "not found:  layer2.1.bn1.running_mean\n",
      "not found:  layer2.1.bn1.running_var\n",
      "not found:  layer2.1.bn1.num_batches_tracked\n",
      "not found:  layer2.1.bn2.weight\n",
      "not found:  layer2.1.bn2.bias\n",
      "not found:  layer2.1.bn2.running_mean\n",
      "not found:  layer2.1.bn2.running_var\n",
      "not found:  layer2.1.bn2.num_batches_tracked\n",
      "not found:  layer3.0.conv1.weight\n",
      "not found:  layer3.0.conv2.weight\n",
      "not found:  layer3.0.bn1.weight\n",
      "not found:  layer3.0.bn1.bias\n",
      "not found:  layer3.0.bn1.running_mean\n",
      "not found:  layer3.0.bn1.running_var\n",
      "not found:  layer3.0.bn1.num_batches_tracked\n",
      "not found:  layer3.0.bn2.weight\n",
      "not found:  layer3.0.bn2.bias\n",
      "not found:  layer3.0.bn2.running_mean\n",
      "not found:  layer3.0.bn2.running_var\n",
      "not found:  layer3.0.bn2.num_batches_tracked\n",
      "not found:  layer3.0.shortcut.0.weight\n",
      "not found:  layer3.0.shortcut.1.weight\n",
      "not found:  layer3.0.shortcut.1.bias\n",
      "not found:  layer3.0.shortcut.1.running_mean\n",
      "not found:  layer3.0.shortcut.1.running_var\n",
      "not found:  layer3.0.shortcut.1.num_batches_tracked\n",
      "not found:  layer3.1.conv1.weight\n",
      "not found:  layer3.1.conv2.weight\n",
      "not found:  layer3.1.bn1.weight\n",
      "not found:  layer3.1.bn1.bias\n",
      "not found:  layer3.1.bn1.running_mean\n",
      "not found:  layer3.1.bn1.running_var\n",
      "not found:  layer3.1.bn1.num_batches_tracked\n",
      "not found:  layer3.1.bn2.weight\n",
      "not found:  layer3.1.bn2.bias\n",
      "not found:  layer3.1.bn2.running_mean\n",
      "not found:  layer3.1.bn2.running_var\n",
      "not found:  layer3.1.bn2.num_batches_tracked\n",
      "not found:  layer4.0.conv1.weight\n",
      "not found:  layer4.0.conv2.weight\n",
      "not found:  layer4.0.bn1.weight\n",
      "not found:  layer4.0.bn1.bias\n",
      "not found:  layer4.0.bn1.running_mean\n",
      "not found:  layer4.0.bn1.running_var\n",
      "not found:  layer4.0.bn1.num_batches_tracked\n",
      "not found:  layer4.0.bn2.weight\n",
      "not found:  layer4.0.bn2.bias\n",
      "not found:  layer4.0.bn2.running_mean\n",
      "not found:  layer4.0.bn2.running_var\n",
      "not found:  layer4.0.bn2.num_batches_tracked\n",
      "not found:  layer4.0.shortcut.0.weight\n",
      "not found:  layer4.0.shortcut.1.weight\n",
      "not found:  layer4.0.shortcut.1.bias\n",
      "not found:  layer4.0.shortcut.1.running_mean\n",
      "not found:  layer4.0.shortcut.1.running_var\n",
      "not found:  layer4.0.shortcut.1.num_batches_tracked\n",
      "not found:  layer4.1.conv1.weight\n",
      "not found:  layer4.1.conv2.weight\n",
      "not found:  layer4.1.bn1.weight\n",
      "not found:  layer4.1.bn1.bias\n",
      "not found:  layer4.1.bn1.running_mean\n",
      "not found:  layer4.1.bn1.running_var\n",
      "not found:  layer4.1.bn1.num_batches_tracked\n",
      "not found:  layer4.1.bn2.weight\n",
      "not found:  layer4.1.bn2.bias\n",
      "not found:  layer4.1.bn2.running_mean\n",
      "not found:  layer4.1.bn2.running_var\n",
      "not found:  layer4.1.bn2.num_batches_tracked\n",
      "not found:  linear.weight\n",
      "not found:  linear.bias\n",
      "not found:  conv1.weight\n",
      "not found:  bn1.weight\n",
      "not found:  bn1.bias\n",
      "not found:  bn1.running_mean\n",
      "not found:  bn1.running_var\n",
      "not found:  bn1.num_batches_tracked\n",
      "not found:  layer1.0.conv1.weight\n",
      "not found:  layer1.0.conv2.weight\n",
      "not found:  layer1.0.bn1.weight\n",
      "not found:  layer1.0.bn1.bias\n",
      "not found:  layer1.0.bn1.running_mean\n",
      "not found:  layer1.0.bn1.running_var\n",
      "not found:  layer1.0.bn1.num_batches_tracked\n",
      "not found:  layer1.0.bn2.weight\n",
      "not found:  layer1.0.bn2.bias\n",
      "not found:  layer1.0.bn2.running_mean\n",
      "not found:  layer1.0.bn2.running_var\n",
      "not found:  layer1.0.bn2.num_batches_tracked\n",
      "not found:  layer1.1.conv1.weight\n",
      "not found:  layer1.1.conv2.weight\n",
      "not found:  layer1.1.bn1.weight\n",
      "not found:  layer1.1.bn1.bias\n",
      "not found:  layer1.1.bn1.running_mean\n",
      "not found:  layer1.1.bn1.running_var\n",
      "not found:  layer1.1.bn1.num_batches_tracked\n",
      "not found:  layer1.1.bn2.weight\n",
      "not found:  layer1.1.bn2.bias\n",
      "not found:  layer1.1.bn2.running_mean\n",
      "not found:  layer1.1.bn2.running_var\n",
      "not found:  layer1.1.bn2.num_batches_tracked\n",
      "not found:  layer3.0.conv1.weight\n",
      "not found:  layer3.0.conv2.weight\n",
      "not found:  layer3.0.bn1.weight\n",
      "not found:  layer3.0.bn1.bias\n",
      "not found:  layer3.0.bn1.running_mean\n",
      "not found:  layer3.0.bn1.running_var\n",
      "not found:  layer3.0.bn1.num_batches_tracked\n",
      "not found:  layer3.0.bn2.weight\n",
      "not found:  layer3.0.bn2.bias\n",
      "not found:  layer3.0.bn2.running_mean\n",
      "not found:  layer3.0.bn2.running_var\n",
      "not found:  layer3.0.bn2.num_batches_tracked\n",
      "not found:  layer3.0.shortcut.0.weight\n",
      "not found:  layer3.0.shortcut.1.weight\n",
      "not found:  layer3.0.shortcut.1.bias\n",
      "not found:  layer3.0.shortcut.1.running_mean\n",
      "not found:  layer3.0.shortcut.1.running_var\n",
      "not found:  layer3.0.shortcut.1.num_batches_tracked\n",
      "not found:  layer3.1.conv1.weight\n",
      "not found:  layer3.1.conv2.weight\n",
      "not found:  layer3.1.bn1.weight\n",
      "not found:  layer3.1.bn1.bias\n",
      "not found:  layer3.1.bn1.running_mean\n",
      "not found:  layer3.1.bn1.running_var\n",
      "not found:  layer3.1.bn1.num_batches_tracked\n",
      "not found:  layer3.1.bn2.weight\n",
      "not found:  layer3.1.bn2.bias\n",
      "not found:  layer3.1.bn2.running_mean\n",
      "not found:  layer3.1.bn2.running_var\n",
      "not found:  layer3.1.bn2.num_batches_tracked\n",
      "not found:  layer4.0.conv1.weight\n",
      "not found:  layer4.0.conv2.weight\n",
      "not found:  layer4.0.bn1.weight\n",
      "not found:  layer4.0.bn1.bias\n",
      "not found:  layer4.0.bn1.running_mean\n",
      "not found:  layer4.0.bn1.running_var\n",
      "not found:  layer4.0.bn1.num_batches_tracked\n",
      "not found:  layer4.0.bn2.weight\n",
      "not found:  layer4.0.bn2.bias\n",
      "not found:  layer4.0.bn2.running_mean\n",
      "not found:  layer4.0.bn2.running_var\n",
      "not found:  layer4.0.bn2.num_batches_tracked\n",
      "not found:  layer4.0.shortcut.0.weight\n",
      "not found:  layer4.0.shortcut.1.weight\n",
      "not found:  layer4.0.shortcut.1.bias\n",
      "not found:  layer4.0.shortcut.1.running_mean\n",
      "not found:  layer4.0.shortcut.1.running_var\n",
      "not found:  layer4.0.shortcut.1.num_batches_tracked\n",
      "not found:  layer4.1.conv1.weight\n",
      "not found:  layer4.1.conv2.weight\n",
      "not found:  layer4.1.bn1.weight\n",
      "not found:  layer4.1.bn1.bias\n",
      "not found:  layer4.1.bn1.running_mean\n",
      "not found:  layer4.1.bn1.running_var\n",
      "not found:  layer4.1.bn1.num_batches_tracked\n",
      "not found:  layer4.1.bn2.weight\n",
      "not found:  layer4.1.bn2.bias\n",
      "not found:  layer4.1.bn2.running_mean\n",
      "not found:  layer4.1.bn2.running_var\n",
      "not found:  layer4.1.bn2.num_batches_tracked\n",
      "not found:  linear.weight\n",
      "not found:  linear.bias\n",
      "not found:  conv1.weight\n",
      "not found:  bn1.weight\n",
      "not found:  bn1.bias\n",
      "not found:  bn1.running_mean\n",
      "not found:  bn1.running_var\n",
      "not found:  bn1.num_batches_tracked\n",
      "not found:  layer1.0.conv1.weight\n",
      "not found:  layer1.0.conv2.weight\n",
      "not found:  layer1.0.bn1.weight\n",
      "not found:  layer1.0.bn1.bias\n",
      "not found:  layer1.0.bn1.running_mean\n",
      "not found:  layer1.0.bn1.running_var\n",
      "not found:  layer1.0.bn1.num_batches_tracked\n",
      "not found:  layer1.0.bn2.weight\n",
      "not found:  layer1.0.bn2.bias\n",
      "not found:  layer1.0.bn2.running_mean\n",
      "not found:  layer1.0.bn2.running_var\n",
      "not found:  layer1.0.bn2.num_batches_tracked\n",
      "not found:  layer1.1.conv1.weight\n",
      "not found:  layer1.1.conv2.weight\n",
      "not found:  layer1.1.bn1.weight\n",
      "not found:  layer1.1.bn1.bias\n",
      "not found:  layer1.1.bn1.running_mean\n",
      "not found:  layer1.1.bn1.running_var\n",
      "not found:  layer1.1.bn1.num_batches_tracked\n",
      "not found:  layer1.1.bn2.weight\n",
      "not found:  layer1.1.bn2.bias\n",
      "not found:  layer1.1.bn2.running_mean\n",
      "not found:  layer1.1.bn2.running_var\n",
      "not found:  layer1.1.bn2.num_batches_tracked\n",
      "not found:  layer2.0.conv1.weight\n",
      "not found:  layer2.0.conv2.weight\n",
      "not found:  layer2.0.bn1.weight\n",
      "not found:  layer2.0.bn1.bias\n",
      "not found:  layer2.0.bn1.running_mean\n",
      "not found:  layer2.0.bn1.running_var\n",
      "not found:  layer2.0.bn1.num_batches_tracked\n",
      "not found:  layer2.0.bn2.weight\n",
      "not found:  layer2.0.bn2.bias\n",
      "not found:  layer2.0.bn2.running_mean\n",
      "not found:  layer2.0.bn2.running_var\n",
      "not found:  layer2.0.bn2.num_batches_tracked\n",
      "not found:  layer2.0.shortcut.0.weight\n",
      "not found:  layer2.0.shortcut.1.weight\n",
      "not found:  layer2.0.shortcut.1.bias\n",
      "not found:  layer2.0.shortcut.1.running_mean\n",
      "not found:  layer2.0.shortcut.1.running_var\n",
      "not found:  layer2.0.shortcut.1.num_batches_tracked\n",
      "not found:  layer2.1.conv1.weight\n",
      "not found:  layer2.1.conv2.weight\n",
      "not found:  layer2.1.bn1.weight\n",
      "not found:  layer2.1.bn1.bias\n",
      "not found:  layer2.1.bn1.running_mean\n",
      "not found:  layer2.1.bn1.running_var\n",
      "not found:  layer2.1.bn1.num_batches_tracked\n",
      "not found:  layer2.1.bn2.weight\n",
      "not found:  layer2.1.bn2.bias\n",
      "not found:  layer2.1.bn2.running_mean\n",
      "not found:  layer2.1.bn2.running_var\n",
      "not found:  layer2.1.bn2.num_batches_tracked\n",
      "not found:  layer4.0.conv1.weight\n",
      "not found:  layer4.0.conv2.weight\n",
      "not found:  layer4.0.bn1.weight\n",
      "not found:  layer4.0.bn1.bias\n",
      "not found:  layer4.0.bn1.running_mean\n",
      "not found:  layer4.0.bn1.running_var\n",
      "not found:  layer4.0.bn1.num_batches_tracked\n",
      "not found:  layer4.0.bn2.weight\n",
      "not found:  layer4.0.bn2.bias\n",
      "not found:  layer4.0.bn2.running_mean\n",
      "not found:  layer4.0.bn2.running_var\n",
      "not found:  layer4.0.bn2.num_batches_tracked\n",
      "not found:  layer4.0.shortcut.0.weight\n",
      "not found:  layer4.0.shortcut.1.weight\n",
      "not found:  layer4.0.shortcut.1.bias\n",
      "not found:  layer4.0.shortcut.1.running_mean\n",
      "not found:  layer4.0.shortcut.1.running_var\n",
      "not found:  layer4.0.shortcut.1.num_batches_tracked\n",
      "not found:  layer4.1.conv1.weight\n",
      "not found:  layer4.1.conv2.weight\n",
      "not found:  layer4.1.bn1.weight\n",
      "not found:  layer4.1.bn1.bias\n",
      "not found:  layer4.1.bn1.running_mean\n",
      "not found:  layer4.1.bn1.running_var\n",
      "not found:  layer4.1.bn1.num_batches_tracked\n",
      "not found:  layer4.1.bn2.weight\n",
      "not found:  layer4.1.bn2.bias\n",
      "not found:  layer4.1.bn2.running_mean\n",
      "not found:  layer4.1.bn2.running_var\n",
      "not found:  layer4.1.bn2.num_batches_tracked\n",
      "not found:  linear.weight\n",
      "not found:  linear.bias\n",
      "not found:  conv1.weight\n",
      "not found:  bn1.weight\n",
      "not found:  bn1.bias\n",
      "not found:  bn1.running_mean\n",
      "not found:  bn1.running_var\n",
      "not found:  bn1.num_batches_tracked\n",
      "not found:  layer1.0.conv1.weight\n",
      "not found:  layer1.0.conv2.weight\n",
      "not found:  layer1.0.bn1.weight\n",
      "not found:  layer1.0.bn1.bias\n",
      "not found:  layer1.0.bn1.running_mean\n",
      "not found:  layer1.0.bn1.running_var\n",
      "not found:  layer1.0.bn1.num_batches_tracked\n",
      "not found:  layer1.0.bn2.weight\n",
      "not found:  layer1.0.bn2.bias\n",
      "not found:  layer1.0.bn2.running_mean\n",
      "not found:  layer1.0.bn2.running_var\n",
      "not found:  layer1.0.bn2.num_batches_tracked\n",
      "not found:  layer1.1.conv1.weight\n",
      "not found:  layer1.1.conv2.weight\n",
      "not found:  layer1.1.bn1.weight\n",
      "not found:  layer1.1.bn1.bias\n",
      "not found:  layer1.1.bn1.running_mean\n",
      "not found:  layer1.1.bn1.running_var\n",
      "not found:  layer1.1.bn1.num_batches_tracked\n",
      "not found:  layer1.1.bn2.weight\n",
      "not found:  layer1.1.bn2.bias\n",
      "not found:  layer1.1.bn2.running_mean\n",
      "not found:  layer1.1.bn2.running_var\n",
      "not found:  layer1.1.bn2.num_batches_tracked\n",
      "not found:  layer2.0.conv1.weight\n",
      "not found:  layer2.0.conv2.weight\n",
      "not found:  layer2.0.bn1.weight\n",
      "not found:  layer2.0.bn1.bias\n",
      "not found:  layer2.0.bn1.running_mean\n",
      "not found:  layer2.0.bn1.running_var\n",
      "not found:  layer2.0.bn1.num_batches_tracked\n",
      "not found:  layer2.0.bn2.weight\n",
      "not found:  layer2.0.bn2.bias\n",
      "not found:  layer2.0.bn2.running_mean\n",
      "not found:  layer2.0.bn2.running_var\n",
      "not found:  layer2.0.bn2.num_batches_tracked\n",
      "not found:  layer2.0.shortcut.0.weight\n",
      "not found:  layer2.0.shortcut.1.weight\n",
      "not found:  layer2.0.shortcut.1.bias\n",
      "not found:  layer2.0.shortcut.1.running_mean\n",
      "not found:  layer2.0.shortcut.1.running_var\n",
      "not found:  layer2.0.shortcut.1.num_batches_tracked\n",
      "not found:  layer2.1.conv1.weight\n",
      "not found:  layer2.1.conv2.weight\n",
      "not found:  layer2.1.bn1.weight\n",
      "not found:  layer2.1.bn1.bias\n",
      "not found:  layer2.1.bn1.running_mean\n",
      "not found:  layer2.1.bn1.running_var\n",
      "not found:  layer2.1.bn1.num_batches_tracked\n",
      "not found:  layer2.1.bn2.weight\n",
      "not found:  layer2.1.bn2.bias\n",
      "not found:  layer2.1.bn2.running_mean\n",
      "not found:  layer2.1.bn2.running_var\n",
      "not found:  layer2.1.bn2.num_batches_tracked\n",
      "not found:  layer3.0.conv1.weight\n",
      "not found:  layer3.0.conv2.weight\n",
      "not found:  layer3.0.bn1.weight\n",
      "not found:  layer3.0.bn1.bias\n",
      "not found:  layer3.0.bn1.running_mean\n",
      "not found:  layer3.0.bn1.running_var\n",
      "not found:  layer3.0.bn1.num_batches_tracked\n",
      "not found:  layer3.0.bn2.weight\n",
      "not found:  layer3.0.bn2.bias\n",
      "not found:  layer3.0.bn2.running_mean\n",
      "not found:  layer3.0.bn2.running_var\n",
      "not found:  layer3.0.bn2.num_batches_tracked\n",
      "not found:  layer3.0.shortcut.0.weight\n",
      "not found:  layer3.0.shortcut.1.weight\n",
      "not found:  layer3.0.shortcut.1.bias\n",
      "not found:  layer3.0.shortcut.1.running_mean\n",
      "not found:  layer3.0.shortcut.1.running_var\n",
      "not found:  layer3.0.shortcut.1.num_batches_tracked\n",
      "not found:  layer3.1.conv1.weight\n",
      "not found:  layer3.1.conv2.weight\n",
      "not found:  layer3.1.bn1.weight\n",
      "not found:  layer3.1.bn1.bias\n",
      "not found:  layer3.1.bn1.running_mean\n",
      "not found:  layer3.1.bn1.running_var\n",
      "not found:  layer3.1.bn1.num_batches_tracked\n",
      "not found:  layer3.1.bn2.weight\n",
      "not found:  layer3.1.bn2.bias\n",
      "not found:  layer3.1.bn2.running_mean\n",
      "not found:  layer3.1.bn2.running_var\n",
      "not found:  layer3.1.bn2.num_batches_tracked\n"
     ]
    }
   ],
   "source": [
    "split_model = [layer_1, layer_2, layer_3, layer_4]\n",
    "\n",
    "# load model params into dictionary\n",
    "state_dict = torch.load(io.get_model_path(\"{}\".format(configs[\"load_model\"])), map_location=configs['device'])\n",
    "\n",
    "# add params to split\n",
    "for l in split_model:\n",
    "    l = io.load_state_dict(l, \n",
    "                    state_dict['model_state_dict'] if 'model_state_dict' in state_dict \n",
    "                    else state_dict['state_dict'] if 'state_dict' in state_dict else state_dict,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.conv2.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.conv2.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.conv2.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.conv2.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.conv2.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.conv2.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.conv2.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.conv2.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# look at state dict keys\n",
    "print(state_dict.keys())\n",
    "for i in split_model:\n",
    "    print(len(l.state_dict().keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into full model\n",
    "model = io.load_state_dict(model, \n",
    "                    state_dict['model_state_dict'] if 'model_state_dict' in state_dict \n",
    "                    else state_dict['state_dict'] if 'state_dict' in state_dict else state_dict,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches: 1000/1000\n",
      "histogram tensor([  -34.6444,  -919.2313,   322.4745,  -964.0338,   461.6558, -1301.9825,\n",
      "         3073.6328,  -932.3021,  -233.5381, -1052.3689], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# compare outputs\n",
    "\n",
    "input = torch.rand(1000, 3, 32, 32, device=torch.device(configs['device'])) # 1k images, 3 channels, 32x32 image (cifar100) \n",
    "\n",
    "# put models into eval mode and on device\n",
    "model.eval()\n",
    "model.to(configs['device'])\n",
    "for l in split_model:\n",
    "    l.eval()\n",
    "    l.to(configs['device'])\n",
    "\n",
    "# make inference \n",
    "with torch.no_grad():\n",
    "        output_full = model(input)\n",
    "\n",
    "        output_split = input\n",
    "        for l in split_model:\n",
    "                output_split = l(output_split)\n",
    "\n",
    "\n",
    "match_count = (torch.argmax(output_split, axis=1) == torch.argmax(output_full, axis=1)).sum().item()\n",
    "label_hist = output_full.sum(0)\n",
    "print(f'Matches: {match_count}/{output_full.size(0)}')\n",
    "print(f'histogram {label_hist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.3076e-04, -3.7590e-04, -7.2394e-04,  ..., -4.0057e-04,\n",
       "           -5.7252e-04, -5.8638e-04],\n",
       "          [-3.1505e-04, -6.5126e-04, -1.0406e-03,  ..., -6.3951e-04,\n",
       "           -6.6972e-04, -8.7693e-04],\n",
       "          [-4.7651e-04, -8.7004e-04, -7.1680e-04,  ..., -8.7867e-04,\n",
       "           -8.2595e-04, -5.9736e-04],\n",
       "          ...,\n",
       "          [-4.7025e-04, -8.1106e-04, -7.3174e-04,  ..., -7.1544e-04,\n",
       "           -6.5507e-04, -6.4034e-04],\n",
       "          [-4.4429e-04, -4.0446e-04, -1.0031e-03,  ..., -6.2399e-04,\n",
       "           -7.6651e-04, -6.1660e-04],\n",
       "          [-3.6429e-04, -5.9499e-04, -6.1644e-04,  ..., -6.4783e-04,\n",
       "           -5.2922e-04, -4.7095e-04]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 1.4846e-04,  4.0250e-04,  4.3564e-04,  ...,  1.8267e-04,\n",
       "            2.1855e-04,  3.2160e-04],\n",
       "          [ 3.9423e-04, -7.2723e-05,  8.9880e-05,  ..., -3.1267e-05,\n",
       "            2.8337e-04,  2.9465e-04],\n",
       "          [ 1.1608e-04,  4.4863e-04,  1.3042e-04,  ...,  1.5676e-04,\n",
       "            2.6396e-04,  9.9035e-05],\n",
       "          ...,\n",
       "          [ 3.3851e-04,  8.2139e-05,  3.6771e-04,  ...,  1.2444e-04,\n",
       "            3.9743e-04,  2.7226e-04],\n",
       "          [-1.6531e-04,  1.7606e-04,  3.1399e-04,  ...,  6.6448e-04,\n",
       "            9.4959e-05,  2.5482e-04],\n",
       "          [ 6.4424e-05,  4.7490e-05, -3.0713e-04,  ..., -2.6912e-04,\n",
       "            5.4240e-05,  1.9183e-06]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[-2.2707e-04, -4.9703e-04, -3.3579e-04,  ..., -5.4183e-04,\n",
       "           -4.7710e-04, -5.1256e-04],\n",
       "          [-3.5037e-04, -8.0254e-04, -5.7332e-04,  ..., -7.7904e-04,\n",
       "           -6.8803e-04, -8.4896e-04],\n",
       "          [-7.5162e-04, -1.0122e-03, -6.6224e-04,  ..., -9.1134e-04,\n",
       "           -6.2732e-04, -8.0326e-04],\n",
       "          ...,\n",
       "          [-3.6526e-04, -3.7573e-04, -5.7426e-04,  ..., -4.5527e-04,\n",
       "           -8.8893e-04, -5.2585e-04],\n",
       "          [-5.1608e-04, -6.4760e-04, -1.0157e-03,  ..., -6.4688e-04,\n",
       "           -8.2366e-04, -5.4142e-04],\n",
       "          [-6.1379e-04, -6.7610e-04, -7.7166e-04,  ..., -5.7463e-04,\n",
       "           -5.5326e-04, -2.6587e-04]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 4.9970e-04,  2.2316e-04,  1.4593e-04,  ...,  4.5868e-04,\n",
       "            2.8623e-04,  4.5185e-04],\n",
       "          [ 5.2866e-04,  3.5285e-04,  6.4864e-04,  ...,  3.0056e-04,\n",
       "            6.0808e-04,  2.1326e-04],\n",
       "          [ 5.1415e-04,  5.0533e-04,  4.9855e-05,  ...,  2.2632e-04,\n",
       "           -1.6174e-05,  1.9113e-04],\n",
       "          ...,\n",
       "          [ 2.1878e-04,  2.6979e-04,  2.0221e-04,  ...,  9.5668e-05,\n",
       "            2.6336e-04,  5.1587e-05],\n",
       "          [ 2.8426e-04,  5.6105e-04,  1.9047e-04,  ...,  5.9528e-05,\n",
       "            2.4280e-04,  5.1911e-04],\n",
       "          [-1.8262e-04,  1.1962e-05, -2.2485e-04,  ..., -2.0405e-04,\n",
       "            1.8958e-04, -1.4219e-04]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[-2.8018e-04, -5.2622e-04, -5.4959e-04,  ..., -2.4526e-04,\n",
       "           -5.7036e-04, -8.1553e-04],\n",
       "          [-4.9058e-04, -7.5929e-04, -5.7648e-04,  ..., -5.0785e-04,\n",
       "           -9.2628e-04, -1.0581e-03],\n",
       "          [-4.2907e-04, -7.3391e-04, -6.7252e-04,  ..., -6.0906e-04,\n",
       "           -8.4638e-04, -8.4685e-04],\n",
       "          ...,\n",
       "          [-6.9851e-04, -6.9054e-04, -4.8546e-04,  ..., -3.0461e-04,\n",
       "           -6.4541e-04, -5.2911e-04],\n",
       "          [-5.7230e-04, -5.7584e-04, -3.4799e-04,  ..., -8.1762e-04,\n",
       "           -7.1547e-04, -7.1264e-04],\n",
       "          [-4.3029e-04, -3.0302e-04, -4.6426e-04,  ..., -6.9618e-04,\n",
       "           -5.7586e-04, -2.1470e-04]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 7.0217e-04,  4.1928e-04,  3.0923e-04,  ...,  1.6131e-04,\n",
       "            2.9207e-04,  3.5042e-04],\n",
       "          [ 1.4280e-04,  1.1912e-05,  3.1493e-04,  ..., -8.1787e-05,\n",
       "            3.3146e-04,  3.1049e-04],\n",
       "          [ 1.8573e-04,  2.4996e-04,  6.2374e-04,  ...,  3.6091e-04,\n",
       "            3.1020e-04,  2.5263e-04],\n",
       "          ...,\n",
       "          [ 4.3588e-05,  1.6780e-04,  4.6524e-04,  ..., -1.7222e-04,\n",
       "           -2.1561e-05,  1.5014e-04],\n",
       "          [ 1.7001e-04,  3.6386e-04,  5.2438e-04,  ...,  5.0324e-04,\n",
       "            3.2545e-04,  1.3048e-04],\n",
       "          [-1.7363e-04, -5.2722e-05, -2.1978e-04,  ..., -8.9096e-06,\n",
       "           -1.4428e-04,  4.2822e-05]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-6.2257e-05, -4.1805e-04, -2.9575e-04,  ..., -4.4577e-04,\n",
       "           -2.9937e-04, -1.7536e-04],\n",
       "          [-3.1783e-04, -3.6836e-04, -3.4523e-04,  ..., -7.5302e-04,\n",
       "           -2.6035e-04, -2.0640e-04],\n",
       "          [ 5.3864e-06, -5.7771e-04, -3.3446e-04,  ..., -2.4197e-04,\n",
       "           -2.0143e-04, -4.9786e-04],\n",
       "          ...,\n",
       "          [-3.1358e-04, -5.9909e-04, -6.4759e-04,  ..., -1.0375e-03,\n",
       "           -8.3816e-04, -6.8935e-04],\n",
       "          [-2.6736e-04, -5.4598e-04, -8.4434e-04,  ..., -1.1219e-03,\n",
       "           -5.7976e-04, -5.5427e-04],\n",
       "          [-3.8347e-04, -7.5412e-04, -7.7285e-04,  ..., -6.4472e-04,\n",
       "           -4.5921e-04, -1.2369e-04]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 5.1075e-04,  5.8272e-04,  4.1774e-04,  ...,  1.9367e-04,\n",
       "            1.5487e-04,  3.9225e-04],\n",
       "          [ 6.4550e-04,  4.6794e-04,  4.5458e-04,  ...,  1.4835e-04,\n",
       "            5.8730e-04, -1.3126e-05],\n",
       "          [ 4.1146e-04,  3.4544e-04, -1.3582e-04,  ...,  2.1738e-04,\n",
       "           -1.4757e-04,  2.4213e-04],\n",
       "          ...,\n",
       "          [ 5.3890e-04,  6.8284e-04,  4.1334e-04,  ...,  3.8803e-04,\n",
       "            4.2773e-04,  2.3582e-04],\n",
       "          [ 8.1938e-05,  2.2470e-04,  3.2595e-04,  ...,  1.9725e-04,\n",
       "            7.1116e-05,  1.4500e-04],\n",
       "          [-1.7648e-04, -1.1714e-04, -6.7917e-06,  ..., -2.8116e-04,\n",
       "            1.0237e-04,  5.0772e-06]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[-4.8347e-04, -6.9524e-04, -3.2999e-04,  ..., -3.7912e-06,\n",
       "           -8.1228e-05, -5.9667e-04],\n",
       "          [-6.6269e-04, -6.6984e-04, -2.8939e-04,  ..., -2.1368e-04,\n",
       "           -9.2002e-04, -8.7750e-04],\n",
       "          [-5.7702e-04, -3.1271e-04, -4.5903e-04,  ..., -4.3265e-04,\n",
       "           -1.1911e-03, -8.4577e-04],\n",
       "          ...,\n",
       "          [-4.3677e-04, -7.2931e-04, -7.7263e-04,  ..., -4.1654e-04,\n",
       "           -5.2639e-04, -5.9711e-04],\n",
       "          [-2.2651e-04, -8.0741e-04, -4.6536e-04,  ..., -2.5430e-04,\n",
       "           -5.1181e-04, -7.8604e-04],\n",
       "          [-4.3319e-04, -6.9288e-04, -4.1811e-04,  ..., -4.2237e-04,\n",
       "           -5.9513e-04, -6.8721e-04]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 2.4104e-04,  5.1529e-04,  3.0577e-04,  ...,  3.4794e-04,\n",
       "            9.0685e-05,  6.3990e-05],\n",
       "          [ 4.6785e-04,  3.9980e-05,  3.2036e-04,  ...,  4.9686e-04,\n",
       "            5.3401e-04,  1.8725e-04],\n",
       "          [-6.6110e-05,  3.9595e-04,  3.6061e-04,  ...,  1.4507e-04,\n",
       "            3.0867e-04,  4.2498e-04],\n",
       "          ...,\n",
       "          [ 4.2666e-04,  3.9482e-05,  1.6358e-04,  ...,  8.9980e-05,\n",
       "            3.0565e-04,  2.4498e-04],\n",
       "          [ 2.5587e-04,  2.0734e-04,  1.4902e-04,  ...,  5.1574e-04,\n",
       "            4.3718e-04,  2.8970e-04],\n",
       "          [-1.7134e-04,  2.0834e-05, -2.3920e-04,  ...,  3.3386e-05,\n",
       "           -2.8228e-04,  1.0078e-04]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[-8.3766e-05, -1.8737e-04, -4.3675e-04,  ..., -5.9311e-04,\n",
       "           -3.8012e-04, -5.2584e-04],\n",
       "          [-2.4258e-04, -4.0783e-04, -6.4773e-04,  ..., -5.0882e-04,\n",
       "           -6.5140e-04, -8.1957e-04],\n",
       "          [-2.7727e-04, -5.1288e-04, -9.1165e-04,  ..., -5.0013e-04,\n",
       "           -5.0570e-04, -9.1139e-04],\n",
       "          ...,\n",
       "          [-1.4046e-04, -4.0805e-04, -6.6127e-04,  ..., -6.4403e-04,\n",
       "           -8.4041e-04, -6.8131e-04],\n",
       "          [-1.7624e-04, -3.3592e-04, -4.9478e-04,  ..., -8.5842e-04,\n",
       "           -6.5722e-04, -6.1120e-04],\n",
       "          [-1.0628e-04, -3.2341e-04, -4.0662e-04,  ..., -8.5852e-04,\n",
       "           -6.3515e-04, -5.2648e-04]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 3.4424e-04,  3.7406e-05,  3.3629e-04,  ...,  9.4933e-05,\n",
       "            9.6889e-05,  1.6517e-04],\n",
       "          [ 3.2294e-04,  2.2187e-04, -6.9021e-05,  ...,  3.8537e-04,\n",
       "            2.3888e-04,  1.4521e-04],\n",
       "          [ 5.8165e-04,  2.6019e-04,  5.0448e-04,  ...,  5.6726e-04,\n",
       "            5.5746e-04,  4.1024e-04],\n",
       "          ...,\n",
       "          [ 2.6152e-04,  4.7297e-04,  5.7987e-04,  ..., -2.0812e-05,\n",
       "            3.8286e-04,  4.4964e-04],\n",
       "          [ 5.7285e-04,  3.7084e-04,  1.1291e-04,  ...,  4.0177e-04,\n",
       "            3.9339e-04, -1.3681e-05],\n",
       "          [ 3.0096e-05, -3.1492e-04,  1.6045e-05,  ...,  2.1026e-05,\n",
       "           -2.9557e-04,  1.6077e-04]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]]], device='cuda:0',\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# go layer by layer to identify mismatch\n",
    "split_model[0].conv1(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Test I/O Logic\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Test I/O Logic\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE\n",
    "\n",
    "# make dir name \n",
    "time_stamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "if len(configs['load_model']) == 0:\n",
    "    folder_name='{}-{}-{}-np{}-pr{}-lcm{}-{}'.format( \n",
    "                configs['data-code'], \n",
    "                configs['model'], \n",
    "                configs['sparsity-type'], \n",
    "                configs['num_partition'], \n",
    "                configs['prune-ratio'], \n",
    "                configs['lambda-comm'],\n",
    "                time_stamp)\n",
    "else:\n",
    "    folder_name = '{}-{}'.format(configs['load_model'][:-3],time_stamp)\n",
    "\n",
    "# make folder \n",
    "folder_path = os.path.join(os.getcwd(), 'assets', 'models',folder_name)\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# save weights\n",
    "index = 0\n",
    "for l in split_model:\n",
    "    fpath = os.path.join(os.getcwd(), 'assets', 'models', folder_path, f'layer_model_{index}.pth')\n",
    "    torch.save(l.state_dict(), fpath)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split models:\n",
      "['cifar10-resnet18-kernel-npv2-pr0.75-lcm0.001-20240615-135016', 'cifar10-resnet18-kernel-npv2-pr0.75-lcm0.001-20240615-141807']\n",
      "\n",
      "loading split model cifar10-resnet18-kernel-npv2-pr0.75-lcm0.001-20240615-135016\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "        BasicBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "       BasicBlock-12           [-1, 64, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 149,824\n",
      "Trainable params: 149,824\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 6.00\n",
      "Params size (MB): 0.57\n",
      "Estimated Total Size (MB): 6.58\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 16, 16]          73,728\n",
      "       BatchNorm2d-2          [-1, 128, 16, 16]             256\n",
      "            Conv2d-3          [-1, 128, 16, 16]         147,456\n",
      "       BatchNorm2d-4          [-1, 128, 16, 16]             256\n",
      "            Conv2d-5          [-1, 128, 16, 16]           8,192\n",
      "       BatchNorm2d-6          [-1, 128, 16, 16]             256\n",
      "        BasicBlock-7          [-1, 128, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]         147,456\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "           Conv2d-10          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-11          [-1, 128, 16, 16]             256\n",
      "       BasicBlock-12          [-1, 128, 16, 16]               0\n",
      "================================================================\n",
      "Total params: 525,568\n",
      "Trainable params: 525,568\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 3.00\n",
      "Params size (MB): 2.00\n",
      "Estimated Total Size (MB): 5.25\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 256, 8, 8]         294,912\n",
      "       BatchNorm2d-2            [-1, 256, 8, 8]             512\n",
      "            Conv2d-3            [-1, 256, 8, 8]         589,824\n",
      "       BatchNorm2d-4            [-1, 256, 8, 8]             512\n",
      "            Conv2d-5            [-1, 256, 8, 8]          32,768\n",
      "       BatchNorm2d-6            [-1, 256, 8, 8]             512\n",
      "        BasicBlock-7            [-1, 256, 8, 8]               0\n",
      "            Conv2d-8            [-1, 256, 8, 8]         589,824\n",
      "       BatchNorm2d-9            [-1, 256, 8, 8]             512\n",
      "           Conv2d-10            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-11            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-12            [-1, 256, 8, 8]               0\n",
      "================================================================\n",
      "Total params: 2,099,712\n",
      "Trainable params: 2,099,712\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 1.50\n",
      "Params size (MB): 8.01\n",
      "Estimated Total Size (MB): 9.63\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 512, 4, 4]       1,179,648\n",
      "       BatchNorm2d-2            [-1, 512, 4, 4]           1,024\n",
      "            Conv2d-3            [-1, 512, 4, 4]       2,359,296\n",
      "       BatchNorm2d-4            [-1, 512, 4, 4]           1,024\n",
      "            Conv2d-5            [-1, 512, 4, 4]         131,072\n",
      "       BatchNorm2d-6            [-1, 512, 4, 4]           1,024\n",
      "        BasicBlock-7            [-1, 512, 4, 4]               0\n",
      "            Conv2d-8            [-1, 512, 4, 4]       2,359,296\n",
      "       BatchNorm2d-9            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-10            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-11            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-12            [-1, 512, 4, 4]               0\n",
      "           Linear-13                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 8,398,858\n",
      "Trainable params: 8,398,858\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 0.75\n",
      "Params size (MB): 32.04\n",
      "Estimated Total Size (MB): 32.85\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# LOAD\n",
    "\n",
    "select = 0\n",
    "\n",
    "layer_output_sizes = [(3,32,32), (64,32,32), (128,16,16), (256,8,8)]\n",
    "\n",
    "model_path = os.path.join(os.getcwd(), 'assets', 'models')\n",
    "filenames = os.listdir(model_path)\n",
    "\n",
    "# get dirs\n",
    "split_model_names = []\n",
    "for filename in filenames: # loop through all the files and folders\n",
    "    if os.path.isdir(os.path.join(model_path, filename)): # check whether the current object is a folder or not\n",
    "        split_model_names.append(filename)\n",
    "\n",
    "print('Split models:')\n",
    "print(split_model_names)\n",
    "print()\n",
    "\n",
    "model_name = split_model_names[select] \n",
    "print(f'loading split model {model_name}')\n",
    "\n",
    "index = 0\n",
    "for l in split_model:\n",
    "    layer_state_dict = torch.load(os.path.join(model_path, model_name, f'layer_model_{index}.pth'))\n",
    "    l = io.load_state_dict(l, layer_state_dict)\n",
    "\n",
    "\n",
    "    summary(l, layer_output_sizes[index])\n",
    "    index += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap_nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
